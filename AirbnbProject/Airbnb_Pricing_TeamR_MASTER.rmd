---
title: "AirBnB Pricing Tool"
author: "Team R"
date: "February 10, 2018"
output:
  html_document:
    css: ../AnalyticsStyles/default.css
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    includes:
      in_header: ../AnalyticsStyles/default.sty
always_allow_html: yes
---

<!-- rmarkdown::render("AirbnbProject/Airbnb_Pricing_TeamR_MASTER.rmd") -->

```{r echo=FALSE, message=FALSE}
make_pdf_file = 0 # SET THIS TO 1 IF WE COMPILE PDF FILE, 0 OTHERWISE (FOR HTML)

source("../AnalyticsLibraries/library.R")
source("../AnalyticsLibraries/heatmapOutput.R")

# Package options
ggthemr('fresh')  # ggplot theme
opts_knit$set(progress=FALSE, verbose=FALSE)
opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.2)
options(knitr.kable.NA = '')
library(MASS)
```

```{r echo=FALSE, message=FALSE}
# Please ENTER the filename
datafile_name = "Data/tomslee_airbnb_amsterdam_1476_2017-07-22.csv"
PricingData <- read.csv(datafile_name, stringsAsFactors = TRUE)
# We turn the data into data.matrix class so that we can easier manipulate it
#PricingData <- data.matrix(PricingData)

# Please ENTER the dependent variable.
dependent_variable = 14 # i.e Price

# Please ENTER the attributes to use as independent variables. 
independent_variables = c(1:13,18:19) # use all the available attributes

max_data_report = 10

# Please ENTER the percentage of data used for estimation
estimation_data_percent = 90
validation_data_percent = 5
test_data_percent = 100-estimation_data_percent-validation_data_percent

# Please ENTER 1 if you want to randomly split the data in estimation and validation/test
random_sampling = 1

# Please ENTER the maximum price for accomodation that shall be considered in the analysis
cutoff = 1000

PricingData <- subset(PricingData, room_type != "Shared room")

```

# The Business Context
AirBnB was founded in 2008 by *Brian Chesky*, *Joe Gebbia*, and *Nathan Blecharczyk* as *AirBed & Breakfast*, an online marketplace and hospitality service for short-term lodging. Over the past years, the share of professional hospitality providers has significantly increased and is now *crowding out* the private providers, threatening AirBnB's value proposition of offering *unique design and personal touch*. Within this context, the marketing department wants to run a campaign to attract more private providers. To do this, they requested the analytics department to create a tool that helps attract potential landlords by helping them understand how much money they could earn with their respective apartments through AirBnb.

As a pilot, Amsterdam was chosen because of the "AirBnB friendly" policy of the local regulators and the high number of short-term visitors. The proposed solution, however, is designed to be city-independent and therefore, an easily replicable process was designed, using *.rmd-Files* and *Github*.


<hr>\clearpage

# The Data
(Data source: http://tomslee.net/airbnb-data-collection-get-the-data. We acknowledge the following: All material is copyright Tom Slee, licensed under a Creative Commons Attribution-NonCommercial 2.5 Canada License.)

The data is collected from the official AirBnB website by *Tom Slee* and provided as datasets for a large number of cities at different times. The considered dataset contains `r nrow(PricingData)` entries with `r length(independent_variables)` independent variables.

Name                       | Description
:--------------------------|:--------------------------------------------------------------------
room_id                    | A unique number identifying an AirBnB listing. The listing has a URL on the AirBnB web site of http://airbnb.com/rooms/room_id
host_id                    | A unique number identifying an AirBnB host. The hostâ€™s page has a URL on the AirBnB web site of http://airbnb.com/users/show/host_id
room_type                  | One of "Entire home" (1), "Private room" (2), or "Shared room" (3)
neighborhood               | A subregion of the city or search area for which the survey is carried out *(In Amsterdam: Bijlmer Centrum, Bijlmer Oost, Bos en Lommer, Buitenveldert / Zuidas, Centrum Oost, Centrum West, De Aker / Nieuw Sloten, De Baarsjes / Oud West, De Pijp / Rivierenbuurt, Gaasperdam / Driemond, Geuzenveld / Slotermeer, Ijburg / Eiland Zeeburg, Noord Oost, Noord West, Noord-West / Noord-Midden, Oostelijk Havengebied / Indische Buurt, Osdorp, Oud Noord, Oud Oost, Slotervaart, Watergraafsmeer, Westerpark, Westpoort)
reviews                    | The number of reviews that a listing has received. As 70% of visits end up with a review, the number of reviews can be used to estimate the number of visits. Note that such an estimate will not be reliable for an individual listing, but over a city as a whole it should be a useful metric of traffic
overall_satisfaction       | The average rating (out of five) that the listing has received from those visitors who left a review
accommodates               | The number of guests a listing can accommodate
bedrooms                   | The number of bedrooms a listing offers
minstay                    | The minimum stay for a visit, as posted by the host
latitude and longitude     | The latitude and longitude of the listing as posted on the AirBnB site
last_modified              | The date and time that the values were read from the AirBnB web site
price                      | The price (in $US) for a night stay




Let's look into the data for a few AirBnBlistings. This is how the first `r min(max_data_report, nrow(PricingData))` out of the total of `r nrow(PricingData)` rows look like (transposed, for convenience):

```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
knitr::kable({
#  df <- t(head(round(PricingData[,independent_variables],2), max_data_report))
  df <- t(head(PricingData[,independent_variables], max_data_report))
  colnames(df) <- sprintf("%02d", 1:ncol(df))
  df
})
```

# Overview Process Steps

**Step 1 - Prepare and split the data**: At the end of this step, three cleaned up datasets should be ready before going to the next step: one set for the estimation, a second step for validation and a last set for testing.

**Step 2 - Exploratory Data Analysis**: In this step, a feeling can be established for the available data. Scatterplots, boxplots and correlation matrices can provide useful insights into the data that will help to build a better regression model.

**Step 3 - Building a Regression Model**: To create the actual model, a suitable algorithm and respective parameters need to be chosen. Steps 3 and 4 are part of an iterative approach that will improve the outcome over time, as the parameters get tweaked. 

**Step 4 - Validate Prediction Quality**: Different methods can be used to determine how good the model predicts a different set of listings (i.e. *validation dataset*).

Only after following these steps, the resulting model can be used to predict the prices for new listings or the *testing dataset*. Let's follow these steps.

## Step 1: Prepare and split the data 
As we aim to finally measure and report the performance of the models on **test data**, we split the data into an estimation sample and two validation samples - using some kind of randomized splitting technique. We used a split of 90% estimation, 5% validation, and 5% test data, in order to keep less than thousand listings for the validation and test sets, keeping them well manageable. While setting up the estimation and validation samples, we are careful to maintain the same balance of the dependent variable (price) categories as in the overall dataset.

The second validation data mimic out-of-sample data, and the performance on this validation set is a better approximation of the performance one should expect in practice from the model. In practice, one should usually iterate the model several times using the first validation sample each time, and at the end make the final assessment of the model using the test sample. In this note, we used less iterations for simplicity. Finally, the second validation data is only used once at the very end before making final business decisions based on the analysis. 


```{r echo=FALSE}
if (random_sampling){
  ids.estimation = sample.int(nrow(PricingData),floor(estimation_data_percent*nrow(PricingData)/100))
  PricingData.non_estimation = setdiff(1:nrow(PricingData),ids.estimation) #setdiff(x,y) returns the elements of x that are not in y
  ids.validation=PricingData.non_estimation[sample.int(length(PricingData.non_estimation), floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(PricingData.non_estimation)))]
  } else {
    ids.estimation=1:floor(estimation_data_percent*nrow(PricingData)/100)
    PricingData.non_estimation = setdiff(1:nrow(PricingData),ids.estimation)
    ids.validation = (tail(ids.estimation,1)+1):(tail(ids.estimation,1) + floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(PricingData.non_estimation)))
    }

ids.test = setdiff(1:nrow(PricingData), union(ids.estimation,ids.validation))

PricingData.estimation = PricingData[ids.estimation,]
PricingData.validation = PricingData[ids.validation,]
PricingData.test = PricingData[ids.test,]
```

We typically refer to the three data samples as **estimation data** (`r estimation_data_percent`% of the data in our case), **validation data**  (`r validation_data_percent`% of the data) and **test data** (the remaining `r 100 - estimation_data_percent  -  validation_data_percent`% of the data).

In our case we use `r nrow(PricingData.estimation)` observations in the *estimation data*, `r nrow(PricingData.validation)` in the *validation data*, and `r nrow(PricingData.test)` in the *test data*. 

## Step 2: Exploratory Data Analysis

A few exploratory - and more importantly **preliminary** -  analyses have been created below; annotation omitted in this draft.


```{r}
thecor = round(cor(data.matrix(PricingData.estimation[c(4,8:12,14,18,19)])),2)
iprint.df(round(thecor,2), scale=TRUE)
```

<!-- plot(PricingData.estimation$neighborhood, PricingData.estimation$price) -->
```{r echo=FALSE, fig.height=4.5}
ggplot(PricingData, aes(x=price)) + geom_histogram(binwidth=50) + ggtitle("Histogram of Prices")
```

In case the data contains outliers (defined as listings with prices >= `r cutoff`), we want to exclude these extraordinarily expensive listings:

```{r}
PricingData.estimation <- subset(PricingData.estimation, price<cutoff)
ggplot(PricingData.estimation, aes(x=price)) + geom_histogram(binwidth=50) + ggtitle("Histogram of Prices")

ggplot(PricingData.estimation, aes(x=reviews, y=price)) + geom_point() + ggtitle("Scatterplot of Reviews and Prices") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r echo=FALSE, fig.height=4.5}
# Determine all neighborhoods that are "under-represented" and remove from estimation data
occurences <- table(PricingData.estimation$neighborhood)
PricingData.estimation <- subset(PricingData.estimation, neighborhood %in% names(occurences[occurences >= 100]))
```

We will exclude data from neighborhoods that are not at least represented with 100 listings.

```{r echo=FALSE, fig.height=4.5}
ggplot(PricingData, aes(x=neighborhood, y=price)) + geom_point() + ggtitle("Scatterplot of Neighborhood and Prices") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r echo=FALSE, fig.height=4.5}
ggplot(PricingData, aes(x=overall_satisfaction, y=price)) + geom_point() + ggtitle("Scatterplot of Satisfaction and Prices")
```

```{r echo=FALSE, fig.height=4.5}
ggplot(PricingData, aes(x=bedrooms, y=price)) + geom_point() + ggtitle("Scatterplot of # of Bedrooms and Prices")
```

```{r echo=FALSE, fig.height=4.5}
# Please ENTER the selected independent variables for which to draw box plots.
boxplots_independent_variables = c(10:12) # use only the PAY_ variables

x1 = PricingData.estimation[,boxplots_independent_variables]

colnames(x1) <- c("Overall Satisfaction", "Accommodates", "Bedrooms") # 1:ncol(x1)

swatch.default <- as.character(swatch())
set_swatch(c(swatch.default[1], colorRampPalette(RColorBrewer::brewer.pal(12, "Paired"))(ncol(x1))))
ggplot(melt(cbind.data.frame(n=1:nrow(x1), x1), id="n"), aes(x=n, y=value, colour=variable)) + geom_boxplot(fill="#FFFFFF", size=0.66, position=position_dodge(1.1*nrow(x1))) + ggtitle("Boxplot for numerical variables")
set_swatch(swatch.default)
```

## Step 3: Building a Regression Model

```{r echo=FALSE, fig.height=4.5}
# Data splitting based on numbers of reviews
PricingData.estimation.0 <- subset(PricingData.estimation, reviews == 0)
PricingData.estimation.non0 <- subset(PricingData.estimation, reviews > 2)

# linear regression
fit <- lm(scale(price)~room_type+neighborhood+reviews+overall_satisfaction+accommodates+bedrooms,data=PricingData.estimation.non0)
summary(fit)
fit.step <- stepAIC(fit,direction = "both")
summary(fit.step)
Prediction <- predict(fit,PricingData.validation)

# Log-linear regression
fit.log <-lm(log(price)~room_type+neighborhood+reviews+overall_satisfaction+log(accommodates)+bedrooms,data=PricingData.estimation.non0)
summary(fit.log)
fit.log.step <- stepAIC(fit.log, direction = "both")
summary(fit.log.step)

# Log-linear regression with interactions
fit.int <-lm(log(price)~room_type+neighborhood+reviews+overall_satisfaction+log(accommodates)*room_type+bedrooms,data=PricingData.estimation.non0)
summary(fit.int)
```

## Step 4: Validate Prediction Quality

# Results Analysis
Looking at the results, it seems as though our model is able to predict the value of an appartment through short-term AirBnB rentals with an adjusted R score of [tbc].
Iterating our model and tweaking the analysis process, we chose to segment the data. For instance, we thought about the incidence of "reviews" on price: in fact, places which have never been booked will be priced less accurately than "mature" properties on the market. Looking at this, we tried to minimize the impact of the data exclusion on our total number of data points. 


# Conclusion
In this project, we tried to predict the price per night of an accomodation, based on variables taken from our data source. As a group, we were able to identify some variables not included in the data which could have been significant: for example, the "premium-ness" of the lodging (equivalent to a hotel's number of stars) would have a strong impact on price.
To this point, we had difficulty in obtaining a high level of accuracy in our predictions.

